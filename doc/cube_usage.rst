=========================================
How can I use the Earth System Data Cube?
=========================================

Technical Dataset Description
=============================

.. Responsible: BC


General Data Cube Format, Content and Organisation
--------------------------------------------------

The binary data format for the Earth System Data Cube (ESDC) in the CAB-LAB project is **netCDF 4 classic**, where the term classic stands for an
underlying HDF-5 format accessed by a netCDF 4 API.

The netCDF file's content and structure follows the `CF-conventions <http://cfconventions.org/cf-conventions/v1.6.0/cf-conventions.html>`_.
That is, there are are always at least three dimensions defined

1. ``lon`` - Always the inner and therefore fastest varying dimension. Defines the **raster width** of spatial images.
2. ``lat`` - Always the second dimension. Defines the **raster height** of spatial images.
3. ``time`` - Time dimension.

There are 1D-variables related to each dimension providing its actual values:

* ``lon(lon)`` and ``lat(lon)`` - longitudes and latitudes in *decimal degrees* defined in a WGS-84 geographical
  coordinate reference system. The spatial grid is homogeneous with the distance between two grid points referred to as
  the Data Cube's **spatial resolution**.
* ``start_time(time)`` and ``end_time(time)`` - Period start and end times given in *days since 2001-01-01 00:00*.
  The increments between two vlaues in time are identical and referred to as the Data Cube's **temporal resolution**.

.. todo:: Norman, you never refer to start_time or end_time after this, just to time. Confusing without any further information. What exactly are start and stop times?
    Also, i guess one wold rather name it start and end as stop implies some action.

There is usually only a single geophysical variable with *shape*\ (``time``, ``lat``, ``lon``) represented by each
netCDF file. So each netCDF file is composed of *length*\ (``time``) spatial images of that variable, where each image
of size *length*\ (``lon``) x *length*\ (``lat``) pixels has been generated by aggregating all source data contributing
to the period given by the Data Cube's temporal resolution.

To limit the size of individual files, the geophysical variables are stored in one file per year. For example,
if the temporal resolution is 0.25 degrees and the the spatial resolution is 8-day periods then there will be up to 46
images of 1440 x 720 pixels in each annual netCDF file. These annual files are stored in dedicated sub-directories
as follows::

    <cube-root-dir>/
        cube.config
        data/
            LAI/
                2001_LAI.nc
                2002_LAI.nc
                ...
                2011_LAI.nc
            Ozone/
                2001_Ozone.nc
                2002_Ozone.nc
                ...
                2011_Ozone.nc
            ...

The names of the geophysical variable in a netCDF file must match the name of its corresponding sub-directory and the
names of the their contained files.

.. todo:: Norman, CF conventions (and COARDS) are rather strict with respect to naming of variables. Check: http://cfconventions.org/Data/cf-standard-names/30/build/cf-standard-name-table.html

The text file ``cube.config`` contains a Data Cube's static configuration such as its temporal and spatial resolution.
Also the spatial coverage is constant, that is, all spatial images are of the same size. Where actual data is missing,
fill values are inserted to expand a data set to the dimensions of the Data Cube.
The fill values in the Data Cube are identical to the ones used in the Data Cube's sources. The same holds for the data types.
While all images for all time periods have the same size, the temporal coverage for a given variable may vary.
Missing spatial images for a given time period are treated as images with all pixels set to a fill value.

The following table contains all possible configuration parameters:

====================  ==============================  ==========================================================
Parameter             Default Value                   Description
====================  ==============================  ==========================================================
``temporal_res``      ``8``                           The constant temporal resolution given as integer days.
``calendar``          ``'gregorian'``                 Defines this Cube's time units.
``ref_time``          ``datetime(2001, 1, 1)``        The Cube's time units are days since this reference date/time.
``start_time``        ``datetime(2001, 1, 1)``        The start date/time of contributing source data.
``end_time``          ``datetime(2011, 1, 1)``        The end date/time of contributing source data.
``spatial_res``       ``0.25``                        The constant spatial resolution given in decimal degrees.
``grid_x0``           ``0``                           The spatial grid's X-offset. *Not used yet.*
``grid_y0``           ``0``                           The spatial grid's Y-offset. *Not used yet.*
``grid_width``        ``1440``                        The spatial grid's width. Must always be 360 / ``spatial_res``.
``grid_height``       ``720``                         The spatial grid's height. Must always be 180 / ``spatial_res``.
``variables``         ``None``                        The variables contained in this Cube.  *Not used yet.*
``file_format``       ``'NETCDF4_CLASSIC'``           The target binary file format.
``compression``       ``False``                       Whether or not the target binary files should be compressed.
``model_version``     ``'0.1'``                       The version of the Data Cube model and configuration.
====================  ==============================  ==========================================================

General Processing Methods Description
--------------------------------------

The Data Cube is generated by the ``cube-cli`` tool. This tools creates a Data Cube for a given configuration
and can be used to subsequently add variables, one by one, to the Cube. Each variable is read from its specific data source and
transformed in time and space to comply to the specification defined by the target Cube's configuration.

The general approach is as follows: For each variable and a given Cube time period:
* Read the variable's data from all contributing sources that have an overlap with the target period;
* Perform temporal aggregation of all contributing spatial images in the original spatial resolution;
* Perform spatial upsampling or downsampling of the image aggregated in time;
* Mask the resulting upsampled/downsampled image by the common land-sea mask;
* Insert the final image for the variable and target time period into the Data Cube.

.. todo:: Fabian: provide scientific justification here for this approach.*

The following sections describe each method used in more detail.

Gap-Filling Approach
####################

The current version (version 0.1, Nov 2015) of the ESDC does not explicitly fill gaps. However, some
gap-filling occurs during temporal aggregation as described below. The CAB-LAB team may provide
gap-filled ESDC versions at a later point in time of the project. Gap-filling is part of the *Data Analytics
Toolkit* and is thus not tackled during Cube generation to retain the information on the original data coverage
as much as possible.

For future Cube versions per-variable gap-filling strategies may be applied. Also, only a spatio-temporal
region of interest may be gap-filled while cells outside this region may be filled by global default values. An instructive example
of such an approach would be the gap-filling of a LAI data set, which only takes place in mid-latitudes while gaps in high-latitudess are
filled with zeros.

.. todo:: Whoever wrote the above should at least reveal the full name of LAI and give a simple explanation why such a gap-filling may make sense at all.
    Moreover, filling gaps with zeros is in fact gap-filling.

Temporal Resampling
###################

Temporal resampling starts on the 1st January of every year so that all the *i*-th spatial images in the ESDC
refer to the same time of the year, namely starting *i* x *temporal resolution*. Source data is collected for every
resulting ESDC target period. If there is more than one contribution in time, then each contribution is weighted
according to the temporal overlap with the target period. Finally, target pixel values are computed by averaging
all weighted values in time not masked by a fill value. By doing so, some temporal gaps are filled implicitly.

.. todo:: Norman: put graphic here showing how weights are determined.*

.. todo:: Norman: put equation here including weights and also respect fill values.*

Spatial Resampling
##################

Spatial re-sampling occurs after temporal re-sampling if the ESDC's spatial
resolution differs from the data source resolution.

If the ESDC's spatial resolution is higher than the data source spatial resolution, source images are **upsampled
by rescaling hereby duplicating original values, but not performing any spatial interpolation**.

If the ESDC's spatial resolution is lower than the data source spatial resolution, source images are **downsampled
by aggregation hereby performing a weighted spatial averaging taking into account missing values**. If there is not an
integer factor between the source and Cube resolution, weights will be found according to the spatial overlap of source
and target cells.

Land-Water Masking
##################

After spatial resampling, a land-water mask is applied to individual variables depending on whether
a variable is defined for water surfaces only, land surfaces only, or both. A common land-water mask is used for all
variables for a given spatial Cube resolution. Masked values are indicated by fill values.



Constraints and Limitations
---------------------------

The Data Cube's approach of transforming all variables onto a common grid greatly facilitates handling and joint analysis
of data sets that originally had different characteristics and were generated under different assumptions.
Regridding, gap-filling, and averaging, however, may alter the information contained in the original data considerably.

The main idea of the ESDC is to provide a consistent and synoptic characterisation of the Earth System at given time steps to promote global analyses.
Therefore, conducting small-scale, high frequency studies that are potentially highly sensible to individual artifacts introduced by data transformation is not
encouraged. The cautious expert user may hence carefully check phenomena close to the Land-Sea mask or in data sparse
regions of the original data. If in doubt, suspicious patterns in the ESDC or unexpected analytical results should be verified with the source data in the native resolution.
We try here as much as possible to conserve the characteristics of the original data, while facilitating data handling and analysis by transformation.

This is a difficult balance to strike that at times involves inconvenient trade-offs. We thus embrace transparency and reproducibility to enable the
informed user to evaluate the validity and consistency of the processed data and strive to offer options for data transformation wherever possible.

.. todo:: Elaborate further! Or at least revise if you feel like it.

Dataset Usage
=============

The standard way of accessing the Data Cube is through the Data Access API. Alternatively, the netcdf files that comprise
 the Data Cube can also be directly read by any other adequate method, e.g. by an implementation of the netcdf library in
 any programming language or suitable viewer software.

Dataset Access Service
----------------------

.. Responsible: BC*

.. todo:: Responsible BC. GB: it is unclear to me what is the difference between this one and the Data access API. Norman, enlighten me!

Data Access API
---------------

.. Responsible: BC

.. todo:: Responsible BC.

.. _DAT:

Data Analytics Toolkit
----------------------

.. todo:: Responsible MPI!

Use Cases and Examples
----------------------

.. Responsible: MPI

.. todo:: Responsible MPI!
    *Remark: code snippets and specific example of how-to*

Constraints and Limitations
---------------------------

.. todo:: Responsible MPI!

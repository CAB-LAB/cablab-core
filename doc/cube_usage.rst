============================
How can I use the Data Cube?
============================

Technical Dataset Description
=============================

*Responsible: BC*


General Data Cube Format, Content and Organisation
--------------------------------------------------

The binary data format for the CAB-LAB Data Cube is **netCDF 4 classic**, where the term classic stands for an
underlying HDF-5 format accessed by a netCDF 4 API.

The netCDF file's content and structure follows the CF-conventions. That is, there are are always at least three
dimensions defined

1. ``lon`` - Always the inner, therefore fastest varying dimension, Provides the **raster width** of spatial images.
2. ``lat`` - Always the second dimension. Provides the **raster height** of spatial images.
3. ``time`` - Time dimension.

There are 1D-variables related to each dimension providing its tabulated values:

* ``lon`` and ``lat`` - longitudes and latitudes in *decimal degrees* defined in a WGS-84 geographical coordinate
  reference system. Values have all the same step width, referred to as the Data Cube's **spatial resolution**.
* ``time`` - Time values given in *days since 2001-01-01 00:00*. Values have all same step width referred to as the
  Data Cube's **temporal resolution**.

There is usually only a single geophysical variable with the shape (``time``, ``lat``, ``lon``) represented by each
netCDF file. So each netCDF file is composed of *length*(``time``) spatial images of that variable, where each image
of size *length*(``lon``) x *length*(``lat``) pixels has been generated by aggregating all source data contributing
to the period given by the Data Cube's temporal resolution.

To limit the size of individual files, the geophysical variables are stored in one file per year. For example,
if the temporal resolution is 0.25 degrees and the the spatial resolution is 8-day periods then there will be up to 46
images of 1440 x 720 pixels in each annual netCDF file. These annual files are stored in dedicated sub-directories
as follows::

    <cube-root-dir>/
        cube.config
        data/
            LAI/
                2001_LAI.nc
                2002_LAI.nc
                ...
                2011_LAI.nc
            Ozone/
                2001_Ozone.nc
                2002_Ozone.nc
                ...
                2011_Ozone.nc
            ...

The names of the geophysical variable in a netCDF file must match the name of it corresponding sub-directory and the
names of the their contained files.

Within an individual Data Cube the temporal and spatial resolutions will be constant. Also the spatial coverage
will be constant, that is, all spatial images will always be of same size. However, fill values may be present to
indicate missing data. While all images for all time periods have the same size, the temporal coverage may be
individual for a given variable. Missing spatial images for a given time period are treated as images with all pixels
set to a fill value.


General Processing Methods Description
--------------------------------------

Resampling and Gap-Filling Approach
###################################


The usual approach we follow for most source variables is to first resample them in time, then resample them in space.

*TODO Fabian: provide scientific justification for this approach.*

Temporal Resampling
###################

Temporal resampling starts on the 1st January of every year so that all the *i*-th spatial images in the Data Cube
refer to the same time of the year, namely starting *i* x *temporal resolution*. We collect source data for every
resampling period. If there are more than one contributions in time than we weight each contribution according to its
temporal overlap. Finally the target pixels are generated by computing the average of all contributing values
in time not masked by a fill value.

*TODO Norman: put graphic here showing how weights are determined.*

*TODO Norman: put equation here including weights and also respect fill values.*

Spatial Resampling
##################

*TODO Norman: write me.*

Individual Layer Descriptions
-----------------------------

*Remark: data source and methods*

LAI and FAPAR
*************

Write me!

Burnt Area
**********

Write me!

Ozone
*****

Write me!

More...
*******

Write me!


Constraints and Limitations
---------------------------

Write me!

Dataset Usage
=============

Write me!

Dataset Access Service
----------------------

*Responsible: BC*

Write me!

Data Access API
---------------

*Responsible: BC*

Write me!

Data Analytics Toolkit
----------------------

*Responsible: MPI*

Write me!

Use Cases and Examples
----------------------

*Responsible: MPI*

*Remark: code snippets and specific example of how-to*

Write me!

Constraints and Limitations
---------------------------

Write me!
